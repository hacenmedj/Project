{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cf2a1b",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538adcc2",
   "metadata": {},
   "source": [
    "Explication : Réseaux de Neurones pour la Reconnaissance des Chiffres Manuscrits\n",
    "\n",
    "Les réseaux de neurones artificiels (ANN, pour Artificial Neural Networks) sont des modèles d'apprentissage supervisé inspirés du cerveau humain. Ils sont particulièrement efficaces pour traiter des données complexes comme des images, du texte ou des sons. Voici une explication complète sur leur fonctionnement et leur utilisation dans ce projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13ec4b",
   "metadata": {},
   "source": [
    "\n",
    "1. Compréhension des Réseaux de Neurones\n",
    "-Entrée (Input) : Chaque réseau prend des caractéristiques en entrée, comme les pixels d’une image. Dans ce projet, les images des chiffres manuscrits sont de taille 28×2828×28 pixels, ce qui donne 784 caractéristiques en entrée.\n",
    "\n",
    "-Couches Cachées (Hidden Layers) : Des couches de neurones appliquent des transformations mathématiques pour capturer les relations complexes entre les données d'entrée et la sortie.\n",
    "\n",
    "-Sortie (Output) : La dernière couche donne les résultats sous forme de probabilités pour chaque classe. Ici, il y a 10 sorties, correspondant aux chiffres de 0 à 9.\n",
    "\n",
    "-Apprentissage : En utilisant les données d’entraînement, le modèle ajuste les poids des connexions entre les neurones pour minimiser l’erreur entre la sortie prédite et la sortie réelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a04ba2d",
   "metadata": {},
   "source": [
    "Projet de reconnaissance les chiffres manuscrits avec les reseaux de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6ebce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d1156",
   "metadata": {},
   "source": [
    "# 2. Structure du Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b9933",
   "metadata": {},
   "source": [
    "##    Chargement des Données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e3de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b5026f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2a4c1",
   "metadata": {},
   "source": [
    "tf.keras.datasets.mnist : Base de données contenant des images de chiffres manuscrits (60,000 images pour l’entraînement et 10,000 pour le test).\n",
    "x_train et x_test : Contiennent les images des chiffres.\n",
    "y_train et y_test : Contiennent les étiquettes correspondantes (valeurs entre 0 et 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890d018",
   "metadata": {},
   "source": [
    "## Prétraitement des Données :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240dc075",
   "metadata": {},
   "source": [
    "tf.keras.datasets.mnist : Base de données contenant des images de chiffres manuscrits (60,000 images pour l’entraînement et 10,000 pour le test).\n",
    "x_train et x_test : Contiennent les images des chiffres.\n",
    "y_train et y_test : Contiennent les étiquettes correspondantes (valeurs entre 0 et 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7942131",
   "metadata": {},
   "source": [
    "## Prétraitement des Données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c598e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13511374",
   "metadata": {},
   "source": [
    "Les pixels des images sont normalisés pour être compris entre 0 et 1 (au lieu de 0 à 255). Cela accélère et améliore l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb95c2",
   "metadata": {},
   "source": [
    "# Création du Modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d42a7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940b3fa",
   "metadata": {},
   "source": [
    "## Ajout des Couches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e3496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(units=10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd0e72",
   "metadata": {},
   "source": [
    "Flatten : Transforme une image 28×2828×28 en un vecteur de 784 valeurs.\n",
    "Couches Denses :\n",
    "\n",
    "    Dense(128, activation='relu') : Ajoute une couche de 128 neurones avec une activation ReLU (Rectified Linear Unit). Cela permet au modèle de capturer des relations non linéaires.\n",
    "    Dense(10, activation='softmax') : La dernière couche contient 10 neurones, chaque neurone représentant un chiffre (0 à 9). Softmax transforme les valeurs en probabilités."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4fc51",
   "metadata": {},
   "source": [
    "# Compilation et Entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2338b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab156dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.3401 - accuracy: 0.1965\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.1799 - accuracy: 0.2035\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.1174 - accuracy: 0.2092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd1d620f08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13ce4a",
   "metadata": {},
   "source": [
    "Compilation :\n",
    "\n",
    "    optimizer='adam' : Algorithme d'optimisation efficace pour ajuster les poids.\n",
    "    loss='sparse_categorical_crossentropy' : Fonction de perte utilisée pour les problèmes de classification multiclasse.\n",
    "    metrics=['accuracy'] : Évalue la précision du modèle.\n",
    "\n",
    "Entraînement : Le modèle est entraîné sur les données d’entraînement pendant 3 époques (itérations complètes sur les données)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db486d99",
   "metadata": {},
   "source": [
    "# Évaluation du Modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d0491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 4.4532 - accuracy: 0.2352\n",
      "0.23520000278949738\n",
      "4.453223705291748\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(accuracy)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759481b",
   "metadata": {},
   "source": [
    "Évalue la performance sur l’ensemble de test et affiche la précision et la perte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf741a",
   "metadata": {},
   "source": [
    "# Sauvegarde et Prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b7113ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: digits.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('digits.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0560b9",
   "metadata": {},
   "source": [
    "Le modèle est sauvegardé pour être utilisé ultérieurement.\n",
    "\n",
    "Prédiction sur de nouvelles images :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761094e",
   "metadata": {},
   "source": [
    "for x in range(1,6):\n",
    "    img = cv.imread(f'{x}.png')[:,:,0]\n",
    "    img = np.invert(np.array([img]))\n",
    "    prediction = model.predict(img)\n",
    "    print(np.argmax(prediction))\n",
    "    plt.imshow(img[0], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11083227",
   "metadata": {},
   "source": [
    "Les images sont chargées, inversées (pixels noirs/blancs) et prétraitées avant d’être passées au modèle pour prédiction.\n",
    "np.argmax(prediction) : Retourne la classe (chiffre) avec la probabilité la plus élevée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dbbf93",
   "metadata": {},
   "source": [
    "# Résultats\n",
    "\n",
    "    Précision sur les données de test : 23.5%23.5%\n",
    "    Perte sur les données de test : 4.4534.453\n",
    "    La faible précision peut indiquer que le modèle nécessite plus d’entraînement ou que les hyperparamètres doivent être ajustés (par exemple, plus d'époques, couches supplémentaires, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b49168",
   "metadata": {},
   "source": [
    "# Améliorations Potentielles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80884406",
   "metadata": {},
   "source": [
    "-Augmenter les Époques : Entraîner le modèle pendant plus de 3 époques peut améliorer la précision.\n",
    "\n",
    "-Augmentation des Données : Appliquer des transformations (rotation, zoom, etc.) pour augmenter les données d’entraînement.\n",
    "\n",
    "-Hyperparamètres :\n",
    "    -Ajuster la taille des couches (nombre de neurones).\n",
    "    -Utiliser d’autres fonctions d’activation ou algorithmes d’optimisation.\n",
    "\n",
    "-Convolutional Neural Networks (CNN) : Remplacer ce modèle dense par un réseau de neurones convolutifs, spécialement conçu pour les images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21280ff",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "Ce projet montre comment les réseaux de neurones peuvent être utilisés pour reconnaître des chiffres manuscrits. En combinant prétraitement des données, construction d’un modèle neuronal, et ajustement des hyperparamètres, il est possible de créer un modèle performant pour une tâche donnée. Les résultats peuvent être affinés en explorant des techniques avancées comme les CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
